# Deep Learning Coursework

Welcome to the **Deep Learning Coursework Repository**! This repository contains concise notes, code examples, and resources covering essential deep learning concepts.

## Concepts Covered

### 1. Neural Networks (NN)
- Basic building blocks of deep learning, including perceptrons, activation functions, and optimization techniques.

### 2. Convolutional Neural Networks (CNNs)
- Specialized for image data, featuring convolution, pooling, and advanced architectures like ResNet.

### 3. Attention Mechanisms
- Focus on relevant input parts using self-attention, widely used in NLP and vision tasks.

### 4. Transformers
- Revolutionizing deep learning with self-attention and parallelism, foundational for models like BERT and GPT.

### 5. Recurrent Neural Networks (RNNs)
- Designed for sequential data, with variants addressing limitations like the vanishing gradient problem.

### 6. Long Short-Term Memory (LSTM)
- An RNN variant enabling long-term sequence learning using gates like forget, input, and output.
